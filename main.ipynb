{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c6a863-5fd5-4825-8fc8-ccc5341747be",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "\n",
    "This is an implementation of Gradient Boosted Trees for continuous datasets\n",
    "\n",
    "First we look at importing the required datasets, then defining helper functions for developing a Regression Tree, then relevant classes defining the Regression Tree implementation. After this, the performance of the Regression Tree is compared with Sklearn's DecisionTreeRegressor, showing that for multiple min_samples_split both implementations show very close mse values with test data. \n",
    "\n",
    "Then we implement a Gradient Boosted Regression Tree with 5 Trees, and using Mango, a Python library used to find hyperparameters for expensive models, we look at some different implementations using Mango. The main regularisation technique used for our tree is the minimum number of samples split in each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373aed9-3bad-4c80-ab98-94f4fab252f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([8], dtype='int64')\n",
      "(14448, 8) (6192, 8) (14448, 1) (6192, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "df.columns = range(len(df.columns))\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=999)\n",
    "y_train = pd.DataFrame(y_train, columns=[y.name])\n",
    "y_test = pd.DataFrame(y_test, columns=[y.name])\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# X_train = pd.read_csv(\"train_x.csv\", header=None)\n",
    "# y_train = pd.read_csv(\"train_y.csv\", header=None)\n",
    "# X_test = pd.read_csv(\"test_x.csv\", header=None)\n",
    "# y_test = pd.read_csv(\"test_y.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cace07-fcd2-4eeb-b59b-8217f64efe27",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Here, we define helper functions for fitting the Regression Tree on some training dataset $X$ and $y$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "068d2924-fd63-40f0-8e6d-c0bae6d63215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The formula for mse can be rewritten, as the ground_truth is the mean of y values.\n",
    "# This function uses the sum of y values, the sum of squared y values, and the number of y values to update mse in O(1)\n",
    "def update_mse(y_sum, y_squared_sum, n):\n",
    "    return ((y_squared_sum/n) - (y_sum / n)**2)\n",
    "    # return ((y_squared_sum/n) - (mean)**2)\n",
    "\n",
    "# Function to find the best split given a dataset, in which the mse of both splits are minimum\n",
    "def best_mse_split(df):\n",
    "    n, features = df.iloc[:, :-1].shape\n",
    "    min_mse = np.inf\n",
    "    best_feature = 0\n",
    "    best_value = 0\n",
    "    best_left_split = []\n",
    "    best_right_split = []\n",
    "\n",
    "    # iterating over every feature (feature column in our dataframe)\n",
    "    for f in range(features):\n",
    "        # we sort the dataframe by the current feature -> O(n log n) where n is the number of examples\n",
    "        df_sorted = df.sort_values(by=f, inplace=False)\n",
    "        y = df_sorted.iloc[:,-1]\n",
    "        total_y_sum = y.sum()\n",
    "        total_y_squared_sum = (y**2).sum()\n",
    "        left_split_y_sum = 0\n",
    "        left_split_y_squared_sum = 0\n",
    "        # iterating over every feature vector/ example in the dataset\n",
    "        for i in range(n-1):  \n",
    "            # this is O(1), instead of recalculating the mse for the dataset, we can incrementally add an example to the left split and remove it from the right\n",
    "            # Since calculating mse with the traditional formula takes O(n), by sorting the current feature, we can incrementally control the size of each split\n",
    "            # and calculate mse of each split in constant time\n",
    "            left_split_y_sum += y.iloc[i]\n",
    "            left_split_y_squared_sum += (y.iloc[i])**2\n",
    "            right_split_y_sum = total_y_sum - left_split_y_sum\n",
    "            right_split_y_squared_sum = total_y_squared_sum - left_split_y_squared_sum\n",
    "            left_n = i + 1\n",
    "            right_n = n - left_n\n",
    "            \n",
    "            # we skip duplicate values, if our current dataframe only contains duplicate feature vectors, the algorithm will try to split the dataframe into two, which should be avoided\n",
    "            if df_sorted.iloc[i,f] == df_sorted.iloc[i+1,f]:\n",
    "                continue\n",
    "\n",
    "            left_mse = update_mse(left_split_y_sum, left_split_y_squared_sum, left_n)\n",
    "            right_mse = update_mse(right_split_y_sum, right_split_y_squared_sum, right_n)\n",
    "            split_mse = ((left_n*left_mse)+(right_n*right_mse))/n\n",
    "\n",
    "            # finding current best split\n",
    "            if split_mse < min_mse:\n",
    "                min_mse = split_mse\n",
    "                best_feature = f\n",
    "                best_value = df_sorted.iloc[i, f]\n",
    "                # finds the indices where the left split and right split are in the original unsorted dataframe respectively\n",
    "                best_left_split = np.where(df.iloc[:, f] <= best_value)[0]\n",
    "                best_right_split = np.where(df.iloc[:, f] > best_value)[0]\n",
    "    \n",
    "    return min_mse, best_feature, best_value, best_left_split, best_right_split\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1b7caa93-3695-4324-8d6f-caa4f3636654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function used to build the tree \n",
    "def build(df, min_samples):\n",
    "    n = df.shape[0]\n",
    "    # stopping condition -> min_samples\n",
    "    # if the size of the current dataframe in this call is too small we return the mean of the ground truth values\n",
    "    # becomes a leaf node in our tree\n",
    "    if n < min_samples:\n",
    "        return np.mean(df.iloc[:,-1])\n",
    "\n",
    "    # find the best mse split for the current dataset\n",
    "    mse, feature, value, left_split, right_split = best_mse_split(df)\n",
    "    \n",
    "    # no split could be found, make it a leaf node\n",
    "    # no non-empty split could be found -> remember if we had duplicate feature vectors for our entire dataset, no split could be found\n",
    "    # as the mse is never updated, so we return the mean of ground truth values\n",
    "    if mse == np.inf:\n",
    "        return np.mean(df.iloc[:,-1])\n",
    "\n",
    "    # recursively build left and right child of current node\n",
    "    # using the left and right split respectively\n",
    "    left_child = build(df.iloc[left_split], min_samples)\n",
    "    right_child = build(df.iloc[right_split], min_samples)\n",
    "\n",
    "    return TreeNode(mse, feature, value, left_child, right_child)\n",
    "\n",
    "# helper function to navigate tree when predicting a new feature vector\n",
    "def navigate_tree(tree, unseen):\n",
    "    # leaf node\n",
    "    if not isinstance(tree,TreeNode):\n",
    "        return tree\n",
    "\n",
    "    feature = tree.feature\n",
    "    value = tree.value\n",
    "\n",
    "    # recursively call navigate tree\n",
    "    if unseen[feature] <= value:\n",
    "        return navigate_tree(tree.left, unseen)\n",
    "    return navigate_tree(tree.right, unseen)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1363e10-d33d-4a51-8c88-42c9a9af1889",
   "metadata": {},
   "source": [
    "### Regression Tree\n",
    "\n",
    "Below we define the classes for a Tree and the custom RegressionTree class, in which we then compare the performance between the RegressionTree class and Scikit's DecisionTreeRegressor, using mse as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d63ba00-5716-4dd2-9238-463856dfa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining custom Tree class, where each node stores the mse and pointers to children\n",
    "class TreeNode:\n",
    "\n",
    "    def __init__(self, mse, feature, value, left, right):\n",
    "        self.mse = mse\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "# RegressionTree class, our main Regression Tree implementation\n",
    "class RegressionTree:\n",
    "\n",
    "    # storing hyperparameter \n",
    "    def __init__(self, min_samples_split):\n",
    "        self.tree = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "\n",
    "    # we must concatenate X and y into one dataset for the build function, so we do not have to do that everytime we want to calculate the best mse split\n",
    "    def fit_tree(self, X, y):\n",
    "        y = y.rename(columns={0: X.shape[1]})\n",
    "        train = pd.concat([X,y], axis=1)\n",
    "        # call recursive build function to create Regression Tree\n",
    "        self.tree = build(train, self.min_samples_split)\n",
    "\n",
    "    # predicting y_values for each feature vector in X_test\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for c, r in X.iterrows():\n",
    "            y.append(navigate_tree(self.tree, r))\n",
    "        return np.array(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bcbd8ee9-bb7a-44db-9f13-61d2e3117f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.498220682144165\n"
     ]
    }
   ],
   "source": [
    "# example usage \n",
    "import time\n",
    "time_start = time.time()\n",
    "rt = RegressionTree(100)\n",
    "rt.fit_tree(X_train, y_train)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "abc1c73d-0a7e-48e4-8648-fdb2d703ebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Regression Tree [0.3770890818150133, 0.36488124820066653, 0.367726984309839, 0.386957383765939, 0.403014212850536, 0.41172716753812144, 0.4164127326689568, 0.4328280747548593, 0.4457439165854728, 0.4533684941844094]\n",
      "Sklearns regression tree [0.36915327689111344, 0.3608922430135572, 0.36442710197187267, 0.38450484025752985, 0.40136222742026934, 0.4100466429725798, 0.4146757834851642, 0.4315985411513649, 0.44544823790228105, 0.4528911646969541]\n",
      "\n",
      "MSE difference between sklearn's Decision Regressor and my Regression Tree: 1.0619058862773123e-05\n"
     ]
    }
   ],
   "source": [
    "# Running time -> a few minutes\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# We create a RegressionTree and DecisionTreeRegressor, using a variety of min_samples_split values (the only hyperparameter for the RegressionTree)\n",
    "# we then fit the trees on X_train and y_train and allow them to make predictions on X_test\n",
    "# we calculate the mse between predictions and y_test, and append them to an array.\n",
    "rt_mse = []\n",
    "scikit_rt_mse = []\n",
    "for i in range(50,501,50):\n",
    "    rt = RegressionTree(i)\n",
    "    rt.fit_tree(X_train, y_train)\n",
    "\n",
    "    scikit_rt = DecisionTreeRegressor(criterion='squared_error', min_samples_split = i)\n",
    "    scikit_rt.fit(X_train, y_train)\n",
    "\n",
    "    rt_prediction = rt.predict(X_test)\n",
    "    rt_mse.append(mean_squared_error(y_test, rt_prediction))\n",
    "    scikit_prediction = scikit_rt.predict(X_test)\n",
    "    scikit_rt_mse.append(mean_squared_error(y_test, scikit_prediction))\n",
    "\n",
    "# Just by printing the arrays, we see the results are very similiar for min_samples_split ranging from 50 to 500\n",
    "print(f\"My Regression Tree {rt_mse}\")\n",
    "print(f\"Sklearns regression tree {scikit_rt_mse}\")\n",
    "# we can go a step further and calculate mse between the two arrays, as mse is just calculating difference in results\n",
    "final_mse = mean_squared_error(rt_mse, scikit_rt_mse)\n",
    "print(\"\")\n",
    "print(f\"MSE difference between sklearn's Decision Regressor and my Regression Tree: {final_mse}\")\n",
    "\n",
    "# extremely small, meaning my implementation is likely correct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665477d0-bb50-40cd-9f3a-2bcf20a45e28",
   "metadata": {},
   "source": [
    "### Ensemble of Regression Trees\n",
    "\n",
    "Next we will look at an Ensemble of Regression Trees implementation which uses the RegressionTree class:\n",
    "\n",
    "To fit the tree, we initially set the residuals to just be the target values $y$ (of the training set). We call a RegressionTree with min_samples_split[$i$], where min_samples_split is an array in which each index represents the min_samples_split hyperparameter of each tree $T_i$.\n",
    "\n",
    "We fit the first tree $T_0$ with $X$_train and the residuals which are just the target values $y$, and then modify the total predictions (currently an array of 0's)s uch that we add the predictions of $T_0$ on $y$. In subsequent iterations, $T_i$ is trained with the residuals, which is the difference between the target values $y$ and the current total predictions $y_pred$, and we of course append the constructed trees to an array.\n",
    "\n",
    "When we want to predict a $y$-value, we just feed each $T_i$ the test data $X$, and add those predictions to a final value $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "146d5f19-226a-4afb-b78b-03ab57d41db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegressionTreeEnsemble class\n",
    "class RegressionTreeEnsemble:\n",
    "\n",
    "    # We store n -> number of trees to be implemented and min_samples_split, an array representing the min_samples_split values for n trees\n",
    "    def __init__(self, n, min_samples_split):\n",
    "        self.n = n\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "\n",
    "    # fit function explained above\n",
    "    def fit_tree(self, X, y):\n",
    "        if not self.n <= 0:\n",
    "            y_pred = pd.DataFrame(0, index=y.index, columns=y.columns)\n",
    "            for i in range(self.n):\n",
    "                residuals = y - y_pred\n",
    "                tree_n = RegressionTree(self.min_samples_split[i])\n",
    "                tree_n.fit_tree(X, residuals)\n",
    "                y_pred += pd.DataFrame(tree_n.predict(X), index=y.index, columns = y.columns)         \n",
    "                self.trees.append(tree_n)\n",
    "\n",
    "    # predict function explained above\n",
    "    def predict(self, X):\n",
    "        if not self.trees:\n",
    "            print(\"test\")\n",
    "            return np.array([])\n",
    "\n",
    "        # first declare y as a matrix of 0's, since we add our predictions onto it from each tree\n",
    "        y = np.full(X.shape[0], 0, dtype=np.float64)\n",
    "        print(y)\n",
    "        for tree in self.trees:\n",
    "            print(tree.predict(X))\n",
    "            y += tree.predict(X)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "47db9ec7-ce1b-46b2-9e26-bc24171f1c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[-0.3654388   0.32357427  0.41958241 ... -0.27450879  0.09375542\n",
      " -0.3654388 ]\n",
      "[ 0.06946423  0.37233534  0.11039601 ... -0.08507303 -0.14142553\n",
      "  0.03686439]\n",
      "[ 0.1882578  -0.11478428 -0.35998773 ...  0.14316987 -0.07072568\n",
      "  0.1882578 ]\n",
      "[ 0.12156484 -0.19243007 -0.57086568 ...  0.18968323 -0.0369005\n",
      "  0.12156484]\n",
      "MSE produced by an Ensemble Regression Tree for min_samples_split = [500, 400, 300, 200, 100]: 0.34227737631410904\n"
     ]
    }
   ],
   "source": [
    "# example usage -> takes a few minutes\n",
    "min_samples = [500, 400, 300, 200, 100]\n",
    "rte = RegressionTreeEnsemble(5, min_samples)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "# print(rte_predictions)\n",
    "print(f\"MSE produced by an Ensemble Regression Tree for min_samples_split = {min_samples}: {mean_squared_error(y_test, rte_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cde34b-7bf7-4242-86f2-7e9620bf7b09",
   "metadata": {},
   "source": [
    "### Hyperparameter Fine-tuning\n",
    "\n",
    "To achieve the best performance out of the Ensemble Regression Tree on our dataset, fine-tuning of the hyperparameter min_samples_split is required. For the RegressionTree implementation, it may be possible to iterate over a range of min_samples_split value and take the one that yields the lowest MSE, but due to how expensive it is to fit an EnsembleRegressionTree (taking a few minutes each) and the fact that each tree can have different min_samples_split values, careful fine-tuning is required to find a good performing set of min_samples_split parameters whilst also not taking days or weeks to find them. To do this, some hyperparameter fine tuning libraries were used:\n",
    "\n",
    "#### Skopt\n",
    "\n",
    "Also known as Scikit Optimize, it has a function gp_minimize, which takes an objective function (which we define in our code) and a set of potential parameters, which for the Ensemble Regression Tree is a range from 2 to 500 for each tree in the Ensemble. It uses Bayesian Optimisation based on a Gaussian Process Model, which first samples the hyperparameter space by evaluating the objective function at random points, and then fits a probabilistic model to predict the objective function in the hyperparameter space. Iteratively, it selects a point of interest and evaluates the objective function at that point, and updates its model to predict where the global minima of the function is. \n",
    "\n",
    "This is used with initially 30 calls to the objective function, which took around 4000 seconds to complete, and did not show promising results.\n",
    "\n",
    "#### Mango\n",
    "\n",
    "Mango is a parallel hyperparameter tuning library that is capable of fine-tuning in parallel and also uses search techniques based on Bayesian Optimisation. This library is in use by ARM with its main feature being parallelisation. \n",
    "\n",
    "This library gave much more promising results than Skopt, however running in parallel does take longer, as we do not split the workload between cores, we let each thread find a minima in parallel, so the number of calls to the objective function is the same for each core as it is for one core.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c787771-a48e-4688-bce4-80877e49e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting arm-mango\n",
      "  Using cached arm_mango-1.4.3-py3-none-any.whl (29 kB)\n",
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrdict>=2.0.1\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from arm-mango) (2.0.2)\n",
      "Requirement already satisfied: scikit_learn>=0.21.3 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from arm-mango) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from arm-mango) (1.13.1)\n",
      "Collecting tqdm>=4.36.1\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from scikit-optimize) (25.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from scikit-optimize) (1.5.1)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from attrdict>=2.0.1->arm-mango) (1.15.0)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "\u001b[K     |████████████████████████████████| 172 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=3.1.0 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from scikit_learn>=0.21.3->arm-mango) (3.6.0)\n",
      "Installing collected packages: PyYAML, tqdm, pyaml, attrdict, scikit-optimize, arm-mango\n",
      "Successfully installed PyYAML-6.0.2 arm-mango-1.4.3 attrdict-2.0.1 pyaml-25.5.0 scikit-optimize-0.10.2 tqdm-4.67.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arm-mango scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "36d39888-a425-4d49-8d8f-8dd743fe6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple objective function to be optimised\n",
    "def obj_func_skopt(min_samples_split):\n",
    "    # uncomment line below if does not work\n",
    "    # min_samples_split = [p0, p1, p2, p3, p4]\n",
    "    model = RegressionTreeEnsemble(5, min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827427c-a8ae-4003-8982-4d56346d0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.18534848 0.97636364]\n",
      "[ 0.00319529  0.11207886  0.19603182 ...  0.15026209 -0.07134906\n",
      "  0.08224575]\n",
      "[ 0.22303895 -0.26485936  0.01530204 ...  0.01687752  0.05273895\n",
      " -0.00360871]\n",
      "[ 0.0500158  -0.10737012 -0.07253413 ...  0.00027411  0.00577622\n",
      "  0.0190893 ]\n",
      "[-0.01213502  0.37074462  0.2513331  ... -0.09823516 -0.15988213\n",
      " -0.01213502]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.00918155 0.98978212]\n",
      "[-0.06635228  0.37629595  0.0550859  ...  0.06758971  0.04894126\n",
      " -0.06635228]\n",
      "[ 0.07110089  0.28668838 -0.10511274 ...  0.14868546  0.0603098\n",
      "  0.07110089]\n",
      "[-0.00394595 -0.20914449  0.1265228  ...  0.00960049 -0.08302613\n",
      " -0.03768355]\n",
      "[-0.03460922  0.08198381  0.02953271 ...  0.1136396   0.03067969\n",
      "  0.17797456]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.90818382 1.71463158 2.58634286 ... 1.75236905 1.18534848 0.90818382]\n",
      "[-0.38877119 -0.08383341  0.20505888 ...  0.06014207 -0.06998391\n",
      " -0.38877119]\n",
      "[ 0.09526997  0.03978228 -0.09613626 ... -0.03381231 -0.09352573\n",
      "  0.09526997]\n",
      "[ 0.10342254 -0.01158592  0.07756161 ... -0.16310727  0.10861175\n",
      " -0.11528603]\n",
      "[ 0.05083215 -0.13038649  0.2517639  ... -0.0438903   0.05737753\n",
      "  0.05083215]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[-0.29211524  0.30342622  0.41004679 ... -0.28695106  0.08606622\n",
      " -0.29211524]\n",
      "[ 0.12064313  0.03930225  0.0727679  ... -0.12905928 -0.08789292\n",
      "  0.1638241 ]\n",
      "[-0.03864698 -0.15210551  0.0036708  ...  0.13846384  0.06228236\n",
      " -0.03864698]\n",
      "[ 0.05172487 -0.10117822  0.17782535 ...  0.08459111 -0.01631989\n",
      "  0.12929237]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[-0.27706561  0.45195943  0.41325661 ...  0.0300474  -0.1000417\n",
      " -0.27706561]\n",
      "[ 0.11103735  0.28357407  0.38680847 ...  0.02767499 -0.22701067\n",
      "  0.11103735]\n",
      "[-0.06394805 -0.1687851   0.23012752 ...  0.0495454   0.15622131\n",
      " -0.07462281]\n",
      "[ 0.07050406 -0.16851869 -0.1509645  ... -0.03318212  0.07026106\n",
      " -0.08502088]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.75236905 1.18534848 0.98978212]\n",
      "[-0.110565   -0.06934736  0.48478229 ... -0.07265105 -0.03587188\n",
      " -0.110565  ]\n",
      "[ 0.08295739 -0.1803164  -0.01984101 ... -0.01462172 -0.0961128\n",
      "  0.08295739]\n",
      "[ 0.00923853  0.41704813 -0.03579765 ...  0.03404919  0.22080419\n",
      "  0.12369258]\n",
      "[-0.02426686 -0.0781152  -0.14623088 ... -0.02845171 -0.19292206\n",
      " -0.08839667]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.27242857 2.11323333 3.17782609 ... 1.83387879 1.00930769 0.86240625]\n",
      "[-0.13177086  0.10554282 -0.12027436 ...  0.04197735 -0.06630135\n",
      " -0.13177086]\n",
      "[-0.24887653 -0.03824144  0.14100352 ...  0.16585601 -0.10356029\n",
      " -0.01053636]\n",
      "[ 0.03851847  0.5034807   0.14289214 ... -0.17782161 -0.02898037\n",
      " -0.31014736]\n",
      "[ 0.01461789  0.02550715  0.04634467 ...  0.0378804  -0.01519474\n",
      "  0.02550715]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.98638122 1.00918155 0.98978212]\n",
      "[-0.27466213  0.36571102  0.27334379 ...  0.01972029 -0.19161073\n",
      " -0.27466213]\n",
      "[ 0.10252028  0.16081986 -0.43502459 ... -0.08153957 -0.09342049\n",
      "  0.16081986]\n",
      "[ 0.12761147 -0.10351657  0.20062553 ...  0.05466827 -0.05433763\n",
      " -0.04097142]\n",
      "[-0.04016584 -0.02447856  0.14770427 ... -0.03422728 -0.1915041\n",
      "  0.18749728]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.18534848 0.98978212]\n",
      "[-0.16183681  0.38092939 -0.12682035 ...  0.07036115 -0.05572089\n",
      "  0.05049565]\n",
      "[-0.11367575 -0.12515632  0.13142782 ... -0.02591916 -0.01331485\n",
      " -0.11367575]\n",
      "[ 0.00677692 -0.07939787 -0.10142411 ...  0.00587671  0.10160712\n",
      "  0.00677692]\n",
      "[ 0.00861084 -0.11855539  0.03057923 ...  0.04073918 -0.01639619\n",
      "  0.081556  ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.0574     2.11323333 3.17782609 ... 1.83387879 1.00930769 0.86240625]\n",
      "[-0.15063557  0.28037024 -0.00157547 ... -0.08165436 -0.13332366\n",
      " -0.03802957]\n",
      "[ 0.01742284 -0.04019529  0.09212121 ... -0.00183059  0.13692\n",
      "  0.01742284]\n",
      "[ 0.14349318 -0.28002548  0.05912486 ...  0.21135816  0.26995041\n",
      "  0.1492634 ]\n",
      "[ 0.01803336 -0.02067543 -0.05133309 ...  0.06525208 -0.06936312\n",
      "  0.01803336]\n",
      "          fun: 0.3303020837527442\n",
      "            x: [np.int64(467), np.int64(312), np.int64(377), np.int64(445), np.int64(152)]\n",
      "    func_vals: [ 3.454e-01  4.079e-01  4.149e-01  3.303e-01  3.568e-01\n",
      "                 3.825e-01  4.721e-01  3.703e-01  3.770e-01  4.380e-01]\n",
      "      x_iters: [[np.int64(136), np.int64(183), np.int64(347), np.int64(299), np.int64(175)], [np.int64(344), np.int64(184), np.int64(251), np.int64(395), np.int64(20)], [np.int64(142), np.int64(99), np.int64(286), np.int64(25), np.int64(366)], [np.int64(467), np.int64(312), np.int64(377), np.int64(445), np.int64(152)], [np.int64(404), np.int64(447), np.int64(157), np.int64(427), np.int64(133)], [np.int64(189), np.int64(418), np.int64(172), np.int64(124), np.int64(137)], [np.int64(44), np.int64(298), np.int64(39), np.int64(8), np.int64(362)], [np.int64(372), np.int64(222), np.int64(462), np.int64(385), np.int64(73)], [np.int64(328), np.int64(35), np.int64(232), np.int64(291), np.int64(137)], [np.int64(61), np.int64(480), np.int64(155), np.int64(15), np.int64(347)]]\n",
      "       models: [GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
      "                                        n_restarts_optimizer=2, noise='gaussian',\n",
      "                                        normalize_y=True, random_state=1992265279)]\n",
      "        space: Space([Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                      Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                      Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                      Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                      Integer(low=2, high=500, prior='uniform', transform='normalize')])\n",
      " random_state: RandomState(MT19937)\n",
      "        specs:     args:                    func: <function obj_func_skopt at 0x14ea67430>\n",
      "                                      dimensions: Space([Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                                                         Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                                                         Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                                                         Integer(low=2, high=500, prior='uniform', transform='normalize'),\n",
      "                                                         Integer(low=2, high=500, prior='uniform', transform='normalize')])\n",
      "                                  base_estimator: GaussianProcessRegressor(kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1], nu=2.5),\n",
      "                                                                           n_restarts_optimizer=2, noise='gaussian',\n",
      "                                                                           normalize_y=True, random_state=1992265279)\n",
      "                                         n_calls: 10\n",
      "                                 n_random_starts: None\n",
      "                                n_initial_points: 10\n",
      "                         initial_point_generator: random\n",
      "                                        acq_func: gp_hedge\n",
      "                                   acq_optimizer: auto\n",
      "                                              x0: None\n",
      "                                              y0: None\n",
      "                                    random_state: RandomState(MT19937)\n",
      "                                         verbose: False\n",
      "                                        callback: None\n",
      "                                        n_points: 10000\n",
      "                            n_restarts_optimizer: 5\n",
      "                                              xi: 0.01\n",
      "                                           kappa: 1.96\n",
      "                                          n_jobs: 1\n",
      "                                model_queue_size: None\n",
      "                                space_constraint: None\n",
      "               function: base_minimize\n",
      "Time taken 3175.846538066864\n"
     ]
    }
   ],
   "source": [
    "# Skopt implementation\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "\n",
    "# this took about an hour\n",
    "search_space = list()\n",
    "for i in range(5):\n",
    "    search_space.append(Integer(2, 500, name=f\"p{i}\"))\n",
    "time_start = time.time()\n",
    "result = gp_minimize(obj_func_skopt, search_space, n_calls=10)\n",
    "print(result)\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "# ok results\n",
    "# fun: 0.3303020837527442\n",
    "# x: [np.int64(467), np.int64(312), np.int64(377), np.int64(445), np.int64(152)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c6795-4dc4-42ca-aff1-151dafe41f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverbrown/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.0574     2.11323333 2.58634286 ... 1.83387879 1.00930769 0.86240625]\n",
      "[-0.12748118 -0.33901002 -0.04496224 ...  0.01423335 -0.1319647\n",
      " -0.04408779]\n",
      "[ 0.0023938   1.62340671 -0.0804055  ...  0.14534637 -0.18999075\n",
      "  0.08476494]\n",
      "[ 0.19535155 -0.08742159  0.07600418 ...  0.0265682   0.02857726\n",
      " -0.22744552]\n",
      "[-0.15285064  0.32538977 -0.02273998 ... -0.09636065  0.00538192\n",
      " -0.15285064]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.27242857 2.11323333 3.17782609 ... 1.83387879 1.00930769 0.86240625]\n",
      "[ 0.00937171  0.1105013  -0.11309459 ...  0.02869235 -0.20712765\n",
      "  0.00937171]\n",
      "[ 0.08167854 -0.07288725  0.00525214 ...  0.00789769  0.13227394\n",
      "  0.08167854]\n",
      "[ 0.11167932 -0.4643877  -0.1361267  ...  0.08284384 -0.11082298\n",
      " -0.1597595 ]\n",
      "[-0.06661407  0.4420307   0.01819847 ...  0.02261816 -0.01004165\n",
      "  0.02470674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[ 0.02631309  0.08285828  0.41634951 ... -0.28697799  0.14159147\n",
      "  0.02631309]\n",
      "[-0.09096693  0.25225772  0.05164206 ...  0.09321147 -0.10408965\n",
      "  0.09589317]\n",
      "[-0.17032554  0.32813618  0.1114164  ... -0.10409002  0.00795214\n",
      " -0.17032554]\n",
      "[ 0.08850054 -0.37228057  0.32772658 ... -0.03453577  0.04366228\n",
      "  0.60037485]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.18534848 0.98978212]\n",
      "[-0.0746065   0.33735427  0.05660657 ... -0.04013535 -0.07438199\n",
      " -0.00736135]\n",
      "[-0.05381285  0.03922477  0.15324455 ... -0.0165271  -0.11882266\n",
      " -0.05381285]\n",
      "[0.13123566 0.07939093 0.09986667 ... 0.12429424 0.02509501 0.13123566]\n",
      "[ 0.05425598  0.04206933  0.04235805 ... -0.04022182  0.11784325\n",
      " -0.07672818]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[-0.27915279  0.32351365  0.41338376 ... -0.29192433  0.0836789\n",
      " -0.27915279]\n",
      "[ 0.0812659   0.05593556 -0.09154314 ... -0.03415996 -0.10238384\n",
      "  0.05471671]\n",
      "[-0.07898998  0.15090783  0.09702823 ... -0.03882474  0.01276542\n",
      "  0.00801753]\n",
      "[-0.11462394  0.3654614   0.03414784 ...  0.02273708  0.05611832\n",
      "  0.14159414]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.0574     2.11323333 3.17782609 ... 1.83387879 1.00930769 0.86240625]\n",
      "[-0.12320778  0.22368752  0.03075557 ...  0.02046242 -0.10369476\n",
      " -0.12320778]\n",
      "[ 0.09476698 -0.39314344  0.10598669 ...  0.01004122  0.01934059\n",
      "  0.09476698]\n",
      "[-0.09250407  0.02957478  0.18971463 ...  0.00851578  0.04702739\n",
      "  0.07498675]\n",
      "[ 0.09953052  0.04246813  0.02569877 ...  0.06258036 -0.03090644\n",
      "  0.09953052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.34505922660458643:  50%|█████     | 1/2 [08:08<08:08, 488.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.18534848 0.98978212]\n",
      "[-0.26963429  0.37258918  0.18770012 ... -0.00170469 -0.11423576\n",
      " -0.26963429]\n",
      "[ 0.09704157 -0.04722873  0.30004708 ...  0.03441733 -0.03854533\n",
      "  0.0771029 ]\n",
      "[ 0.00034336 -0.02866799 -0.1342181  ...  0.23342681 -0.02792986\n",
      "  0.07789917]\n",
      "[-0.15482016  0.04436585  0.03993954 ... -0.1049585  -0.08105145\n",
      "  0.04436585]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 2.11323333 2.58634286 ... 1.75236905 1.00930769 0.97636364]\n",
      "[-0.10646542  0.16225     0.05172353 ... -0.00276896 -0.04175478\n",
      " -0.23482536]\n",
      "[ 0.02222249 -0.07731158 -0.27063673 ...  0.1161701   0.16104527\n",
      "  0.02222249]\n",
      "[ 0.0028037   0.01201037  0.08214921 ...  0.03816071 -0.06219864\n",
      " -0.03236702]\n",
      "[ 0.15141331 -0.25314721  0.23411783 ...  0.06139926 -0.0673281\n",
      "  0.09919103]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 2.11323333 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.32480891  0.76495383  0.09902037 ...  0.14053113 -0.01193254\n",
      " -0.32480891]\n",
      "[ 0.08335909 -0.04727103 -0.05204831 ... -0.01939074  0.07034541\n",
      "  0.08335909]\n",
      "[-0.05988481 -0.18168084  0.26592545 ...  0.15392724  0.03375336\n",
      " -0.05988481]\n",
      "[ 0.01561331 -0.16365457  0.07405667 ...  0.09906679  0.01534974\n",
      "  0.03334833]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.18534848 0.98978212]\n",
      "[-0.13044879  1.05121588  1.00205919 ...  0.13215321 -0.15826983\n",
      "  0.03221788]\n",
      "[ 0.01797955 -0.03013377 -0.06906904 ... -0.05344472  0.01412161\n",
      "  0.01797955]\n",
      "[-0.04521975 -0.16554578 -0.17801328 ...  0.06341136 -0.06574074\n",
      "  0.18453278]\n",
      "[-0.00784127  0.04730315 -0.06742589 ...  0.01675371 -0.02440388\n",
      " -0.00784127]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.34505922660458643: 100%|██████████| 2/2 [19:38<00:00, 589.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of parameters: {'p0': 260, 'p1': 462, 'p2': 373, 'p3': 322, 'p4': 389} and objective: 0.34505922660458643\n",
      "Time taken 1673.7737519741058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mango implementation \n",
    "from mango import Tuner, scheduler\n",
    "\n",
    "param_space = dict()\n",
    "for i in range(5):\n",
    "    param_space[f'p{i}'] = range(2,500)\n",
    "\n",
    "# Using 4 threads/cores and running in parallel -> 8 iterations total technically\n",
    "config = {\n",
    "    'num_iteration': 2,  \n",
    "    'batch_size': 4     \n",
    "}\n",
    "\n",
    "\n",
    "@scheduler.parallel(n_jobs=4)\n",
    "def obj_func_mango(**params):\n",
    "    min_samples_split = [params['p0'],params['p1'],params['p2'],params['p3'],params['p4']]\n",
    "    model = RegressionTreeEnsemble(5, min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse\n",
    "\n",
    "# Took about 0.5 hours (less iterations than skopt)\n",
    "tuner = Tuner(param_space, obj_func_mango, config)\n",
    "time_start = time.time()\n",
    "results = tuner.minimize()  # Run Tuner\n",
    "best_params = results[\"best_params\"]\n",
    "best_objective = results[\"best_objective\"]\n",
    "print(f'Optimal value of parameters: {best_params} and objective: {best_objective}')\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "\n",
    "# Best score: 0.34505922660458643: 100%|██████████| 2/2 [19:38<00:00, 589.42s/it]\n",
    "# Optimal value of parameters: {'p0': 260, 'p1': 462, 'p2': 373, 'p3': 322, 'p4': 389} and objective: 0.34505922660458643\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba1494-c660-4506-b488-07de064c41b2",
   "metadata": {},
   "source": [
    "### Another Approach\n",
    "\n",
    "To try get below 0.5 mse, we opted for finding the hyperparameters for each tree in the Ensemble one at a time instead of all at once. We alter our objective function to instead fit an Ensemble Tree with 5 trees, to fit an Ensemble with len(min_samples_split). And then we tell our optimiser to optimise on 1 tree first, finding the optimal min_samples_split $m_0$ for $T_0$, and then we tell our optimiser to optimise on 2 trees, where $m_0$ is already given and the optimiser must find $m_1$, so at each $T_i$ we are trying to find $m_i$ only and we are given all $m_0$ to $m_{i-1}$ already.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa82d8-2d1c-4b39-be07-2b48442716a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding minimizer for tree 1\n",
      "[]\n",
      "[]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.00918155 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.18534848 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.27242857 2.11323333 3.17782609 ... 1.83387879 1.00930769 0.86240625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.36555691265322615:  50%|█████     | 1/2 [00:46<00:46, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 2.58634286 ... 1.86397585 1.00918155 0.98978212]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.93895918 1.71463158 2.58634286 ... 1.75236905 1.18534848 0.93895918]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.36555691265322615: 100%|██████████| 2/2 [01:27<00:00, 43.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding minimizer for tree 2\n",
      "[116]\n",
      "[np.float64(0.36555691265322615)]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.02911859\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.02911859\n",
      "  0.06721281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.09825564 -0.05980454\n",
      "  0.02181848]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.09825564 -0.05980454\n",
      " -0.01456435]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.09825564 -0.05980454\n",
      " -0.01456435]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.02911859\n",
      "  0.06721281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.34925776746813153:  50%|█████     | 1/2 [01:51<01:51, 111.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.55360954  0.10997682  0.49585622 ...  0.10761099 -0.03580995\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.40375319  0.08304483  0.49585622 ...  0.10761099 -0.04065376\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[ 0.02659776  0.03805154 -0.10156472 ... -0.13858249  0.11805551\n",
      "  0.12963315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.3486166679823877: 100%|██████████| 2/2 [04:48<00:00, 144.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding minimizer for tree 3\n",
      "[116, 242]\n",
      "[np.float64(0.36555691265322615), np.float64(0.3486166679823877)]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[ 0.05534019  0.35661798  0.04344781 ...  0.26604287 -0.12460021\n",
      "  0.05534019]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.02841575  0.35661798 -0.08836415 ...  0.14904206 -0.04021931\n",
      " -0.02841575]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798 -0.08836415 ...  0.14904206 -0.04021931\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798 -0.08836415 ...  0.14904206 -0.04021931\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[ 0.1762982   0.35661798 -0.08836415 ...  0.14904206 -0.12460021\n",
      "  0.1762982 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.3577155327097316:  50%|█████     | 1/2 [03:03<03:03, 183.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798 -0.08836415 ...  0.14904206 -0.04021931\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[ 0.048679    0.35661798 -0.08836415 ...  0.14904206 -0.057761\n",
      "  0.048679  ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[ 0.1762982   0.35661798 -0.08836415 ...  0.14904206 -0.12460021\n",
      "  0.1762982 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.3573467048066693: 100%|██████████| 2/2 [06:53<00:00, 206.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding minimizer for tree 4\n",
      "[116, 242, 419]\n",
      "[np.float64(0.36555691265322615), np.float64(0.3486166679823877), np.float64(0.3573467048066693)]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.02263946 -0.0741023   0.1494608  ... -0.05731679 -0.02248108\n",
      "  0.02263946]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.27349502  0.1494608  ... -0.21524353 -0.08853027\n",
      "  0.02132182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[ 0.02263946 -0.0741023   0.1494608  ... -0.05731679 -0.02248108\n",
      "  0.02263946]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.02263946 -0.0741023   0.1494608  ... -0.05731679 -0.02248108\n",
      "  0.02263946]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.21524353 -0.08853027\n",
      " -0.01996273]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.14081391 -0.27349502  0.31446673 ... -0.21524353 -0.08853027\n",
      "  0.04541105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.35729625485187505:  50%|█████     | 1/2 [05:39<05:39, 339.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[ 0.02263946 -0.0741023   0.1494608  ... -0.05731679 -0.02248108\n",
      "  0.02263946]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.02248108\n",
      " -0.01996273]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.26327713 -0.27349502  0.29145879 ... -0.18718604 -0.05796914\n",
      "  0.16035414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.35710751617293346: 100%|██████████| 2/2 [11:00<00:00, 330.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding minimizer for tree 5\n",
      "[116, 242, 419, 279]\n",
      "[np.float64(0.36555691265322615), np.float64(0.3486166679823877), np.float64(0.3573467048066693), np.float64(0.35710751617293346)]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.027285    0.03853506 -0.11223907 ...  0.06678096 -0.09510747\n",
      "  0.027285  ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.15873797  0.04898229 -0.24581255 ...  0.07411397 -0.09510747\n",
      "  0.15873797]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.0334536   0.03853506 -0.10364481 ...  0.06678096  0.0117054\n",
      "  0.0334536 ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.04022054  0.03853506 -0.10364481 ...  0.06678096  0.0117054\n",
      "  0.04022054]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.05878982  0.03853506 -0.10364481 ...  0.06678096  0.0117054\n",
      "  0.05878982]\n",
      "[ 0.027285    0.03853506 -0.08748839 ...  0.06678096 -0.09510747\n",
      "  0.027285  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.36528084045144876:  50%|█████     | 1/2 [08:02<08:02, 482.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.05878982  0.03853506 -0.10364481 ...  0.06678096  0.0117054\n",
      "  0.05878982]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.027285    0.03853506 -0.10364481 ...  0.06678096 -0.09510747\n",
      "  0.027285  ]\n",
      "[ 0.15873797  0.04898229 -0.24581255 ...  0.07411397 -0.09510747\n",
      "  0.15873797]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.97636364 1.71463158 2.58634286 ... 1.75236905 1.10504348 0.97636364]\n",
      "[-0.29358103  0.10997682  0.14921936 ...  0.04768359 -0.04896811\n",
      "  0.06721281]\n",
      "[-0.02841575  0.35661798  0.0129173  ...  0.14904206 -0.00837055\n",
      " -0.02841575]\n",
      "[ 0.0866767  -0.0741023   0.1494608  ... -0.08197448 -0.08853027\n",
      " -0.01996273]\n",
      "[ 0.15873797 -0.05327399 -0.24581255 ...  0.11068884 -0.09510747\n",
      "  0.15873797]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.36528084045144876: 100%|██████████| 2/2 [15:56<00:00, 478.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal min_samples_split array: [116, 242, 419, 279, 371]\n",
      "The best mse for each tree: [np.float64(0.36555691265322615), np.float64(0.3486166679823877), np.float64(0.3573467048066693), np.float64(0.35710751617293346), np.float64(0.36528084045144876)]\n",
      "Time taken 4443.088612794876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# new objective function\n",
    "from mango import Tuner, scheduler\n",
    "\n",
    "@scheduler.parallel(n_jobs=4)\n",
    "def obj_func_mango_two(**params):\n",
    "    min_samples_split =  []\n",
    "    for i in range(len(params)):\n",
    "        min_samples_split.append(params[f'p{i}'])\n",
    "    model = RegressionTreeEnsemble(len(min_samples_split), min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse\n",
    "\n",
    "current_optimal_params = []\n",
    "optimal_params_mse = []\n",
    "\n",
    "time_start = time.time()\n",
    "# iterating over each tree we want to find min_samples_split value for\n",
    "for n in range(1,6):\n",
    "    print(f\"finding minimizer for tree {n}\")\n",
    "    print(current_optimal_params)\n",
    "    print(optimal_params_mse)\n",
    "    param_space = dict()\n",
    "    # define the parameter space with values ranging from 2 to 500\n",
    "    for i in range(n):\n",
    "        param_space[f'p{i}'] = range(2,500)\n",
    "    # then, if we have already found optimal parameters for some trees we replace them in the parameter space with just a singular value\n",
    "    for i in range(len(current_optimal_params)):\n",
    "        param_space[f'p{i}'] = range(current_optimal_params[i], current_optimal_params[i]+1)\n",
    "\n",
    "    # This time 4 cores run in parallel and 20 calls to the objective function are made\n",
    "    config = {\n",
    "        'num_iteration': 2,  \n",
    "        'batch_size': 4 \n",
    "    }\n",
    "\n",
    "    tuner = Tuner(param_space, obj_func_mango_two, config)\n",
    "    results = tuner.minimize()  # Run Tuner\n",
    "    # we store the best mss in an array, and the mse for each mss\n",
    "    best_params = results[\"best_params\"]\n",
    "    current_optimal_params.append(best_params[f\"p{n-1}\"])\n",
    "    optimal_params_mse.append(results[\"best_objective\"])\n",
    "\n",
    "\n",
    "print(f\"Optimal min_samples_split array: {current_optimal_params}\")\n",
    "print(f\"The best mse for each tree: {optimal_params_mse}\")\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "# 75 mins\n",
    "# Best score: 0.36528084045144876: 100%|██████████| 2/2 [15:56<00:00, 478.24s/it]\n",
    "# Optimal min_samples_split array: [116, 242, 419, 279, 371]\n",
    "# num_iteration 2, batch_size 4, n_jobs 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66ba30-4464-4f8b-8807-3efbf1dda921",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Our best performing optimiser was Skopt, which found an MSE of $0.3303$ when evaluated on test data.\n",
    "The min_samples_split array is $[467,312,377,445,152]$, we can see that the training data is very large and prefers higher mss values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5d601-f5ff-4628-b110-c57d492cb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.98978212 1.55701765 1.72766144 ... 2.03436601 1.00918155 0.98978212]\n",
      "[-0.29211524  0.30342622  0.41004679 ... -0.28695106  0.08606622\n",
      " -0.29211524]\n",
      "[ 0.12064313  0.03930225  0.0727679  ... -0.12905928 -0.08789292\n",
      "  0.1638241 ]\n",
      "[-0.03864698 -0.15210551  0.0036708  ...  0.13846384  0.06228236\n",
      " -0.03864698]\n",
      "[ 0.05172487 -0.10117822  0.17782535 ...  0.08459111 -0.01631989\n",
      "  0.12929237]\n",
      "MSE produced by an Ensemble Regression Tree with best parameters found: 0.3303020837527442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_samples = [467,312,377,445,152]\n",
    "rte = RegressionTreeEnsemble(5, min_samples)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "print(f\"MSE produced by an Ensemble Regression Tree with best parameters found: {mean_squared_error(y_test, rte_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "24cf9618-9b92-4703-a854-f80f97358368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE produced by a Regression Tree with best parameter found: 0.44849568967978215\n"
     ]
    }
   ],
   "source": [
    "# In comparison with a single tree\n",
    "rte = RegressionTree(467)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "print(f\"MSE produced by a Regression Tree with best parameter found: {mean_squared_error(y_test, rte_predictions)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
