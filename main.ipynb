{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c6a863-5fd5-4825-8fc8-ccc5341747be",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "\n",
    "This is an implementation of Gradient Boosted Trees for continuous datasets\n",
    "\n",
    "First we look at importing the required datasets, then defining helper functions for developing a Regression Tree, then relevant classes defining the Regression Tree implementation. After this, the performance of the Regression Tree is compared with Sklearn's DecisionTreeRegressor, showing that for multiple min_samples_split both implementations show very close mse values with test data. \n",
    "\n",
    "Then we implement a Gradient Boosted Regression Tree with 5 Trees, and using Mango, a Python library used to find hyperparameters for expensive models, we look at some different implementations using Mango. The main regularisation technique used for our tree is the minimum number of samples split in each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa3d37bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: /usr/local/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "# your python path if not exported to path\n",
    "!/usr/local/bin/python3.9 -m pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373aed9-3bad-4c80-ab98-94f4fab252f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/usr/bin/python3\n",
      "['/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python39.zip', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload', '', '/Users/oliverbrown/Library/Python/3.9/lib/python/site-packages', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages']\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 34.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/oliverbrown/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[K     |████████████████████████████████| 347 kB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Installing collected packages: tzdata, pytz, numpy, pandas\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_x.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_x.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_y.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_x.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_x.csv'"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy pandas  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"train_x.csv\", header=None)\n",
    "y_train = pd.read_csv(\"train_y.csv\", header=None)\n",
    "X_test = pd.read_csv(\"test_x.csv\", header=None)\n",
    "y_test = pd.read_csv(\"test_y.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cace07-fcd2-4eeb-b59b-8217f64efe27",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Here, we define helper functions for fitting the Regression Tree on some training dataset $X$ and $y$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d2924-fd63-40f0-8e6d-c0bae6d63215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The formula for mse can be rewritten, as the ground_truth is the mean of y values.\n",
    "# This function uses the sum of y values, the sum of squared y values, and the number of y values to update mse in O(1)\n",
    "def update_mse(y_sum, y_squared_sum, n):\n",
    "    return ((y_squared_sum/n) - (y_sum / n)**2)\n",
    "    # return ((y_squared_sum/n) - (mean)**2)\n",
    "\n",
    "# Function to find the best split given a dataset, in which the mse of both splits are minimum\n",
    "def best_mse_split(df):\n",
    "    n, features = df.iloc[:, :-1].shape\n",
    "    min_mse = np.inf\n",
    "    best_feature = 0\n",
    "    best_value = 0\n",
    "    best_left_split = []\n",
    "    best_right_split = []\n",
    "\n",
    "    # iterating over every feature (feature column in our dataframe)\n",
    "    for f in range(features):\n",
    "        # we sort the dataframe by the current feature -> O(n log n) where n is the number of examples\n",
    "        df_sorted = df.sort_values(by=f, inplace=False)\n",
    "        y = df_sorted.iloc[:,-1]\n",
    "        total_y_sum = y.sum()\n",
    "        total_y_squared_sum = (y**2).sum()\n",
    "        left_split_y_sum = 0\n",
    "        left_split_y_squared_sum = 0\n",
    "        # iterating over every feature vector/ example in the dataset\n",
    "        for i in range(n-1):  \n",
    "            # this is O(1), instead of recalculating the mse for the dataset, we can incrementally add an example to the left split and remove it from the right\n",
    "            # Since calculating mse with the traditional formula takes O(n), by sorting the current feature, we can incrementally control the size of each split\n",
    "            # and calculate mse of each split in constant time\n",
    "            left_split_y_sum += y.iloc[i]\n",
    "            left_split_y_squared_sum += (y.iloc[i])**2\n",
    "            right_split_y_sum = total_y_sum - left_split_y_sum\n",
    "            right_split_y_squared_sum = total_y_squared_sum - left_split_y_squared_sum\n",
    "            left_n = i + 1\n",
    "            right_n = n - left_n\n",
    "            \n",
    "            # we skip duplicate values, if our current dataframe only contains duplicate feature vectors, the algorithm will try to split the dataframe into two, which should be avoided\n",
    "            if df_sorted.iloc[i,f] == df_sorted.iloc[i+1,f]:\n",
    "                continue\n",
    "\n",
    "            left_mse = update_mse(left_split_y_sum, left_split_y_squared_sum, left_n)\n",
    "            right_mse = update_mse(right_split_y_sum, right_split_y_squared_sum, right_n)\n",
    "            split_mse = ((left_n*left_mse)+(right_n*right_mse))/n\n",
    "\n",
    "            # finding current best split\n",
    "            if split_mse < min_mse:\n",
    "                min_mse = split_mse\n",
    "                best_feature = f\n",
    "                best_value = df_sorted.iloc[i, f]\n",
    "                # finds the indices where the left split and right split are in the original unsorted dataframe respectively\n",
    "                best_left_split = np.where(df.iloc[:, f] <= best_value)[0]\n",
    "                best_right_split = np.where(df.iloc[:, f] > best_value)[0]\n",
    "    \n",
    "    return min_mse, best_feature, best_value, best_left_split, best_right_split\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7caa93-3695-4324-8d6f-caa4f3636654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function used to build the tree \n",
    "def build(df, min_samples):\n",
    "    n = df.shape[0]\n",
    "    # stopping condition -> min_samples\n",
    "    # if the size of the current dataframe in this call is too small we return the mean of the ground truth values\n",
    "    # becomes a leaf node in our tree\n",
    "    if n < min_samples:\n",
    "        return np.mean(df.iloc[:,-1])\n",
    "\n",
    "    # find the best mse split for the current dataset\n",
    "    mse, feature, value, left_split, right_split = best_mse_split(df)\n",
    "    \n",
    "    # no split could be found, make it a leaf node\n",
    "    # no non-empty split could be found -> remember if we had duplicate feature vectors for our entire dataset, no split could be found\n",
    "    # as the mse is never updated, so we return the mean of ground truth values\n",
    "    if mse == np.inf:\n",
    "        return np.mean(df.iloc[:,-1])\n",
    "\n",
    "    # recursively build left and right child of current node\n",
    "    # using the left and right split respectively\n",
    "    left_child = build(df.iloc[left_split], min_samples)\n",
    "    right_child = build(df.iloc[right_split], min_samples)\n",
    "\n",
    "    return TreeNode(mse, feature, value, left_child, right_child)\n",
    "\n",
    "# helper function to navigate tree when predicting a new feature vector\n",
    "def navigate_tree(tree, unseen):\n",
    "    # leaf node\n",
    "    if not isinstance(tree,TreeNode):\n",
    "        return tree\n",
    "\n",
    "    feature = tree.feature\n",
    "    value = tree.value\n",
    "\n",
    "    # recursively call navigate tree\n",
    "    if unseen[feature] <= value:\n",
    "        return navigate_tree(tree.left, unseen)\n",
    "    return navigate_tree(tree.right, unseen)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1363e10-d33d-4a51-8c88-42c9a9af1889",
   "metadata": {},
   "source": [
    "### Regression Tree\n",
    "\n",
    "Below we define the classes for a Tree and the custom RegressionTree class, in which we then compare the performance between the RegressionTree class and Scikit's DecisionTreeRegressor, using mse as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63ba00-5716-4dd2-9238-463856dfa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining custom Tree class, where each node stores the mse and pointers to children\n",
    "class TreeNode:\n",
    "\n",
    "    def __init__(self, mse, feature, value, left, right):\n",
    "        self.mse = mse\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "# RegressionTree class, our main Regression Tree implementation\n",
    "class RegressionTree:\n",
    "\n",
    "    # storing hyperparameter \n",
    "    def __init__(self, min_samples_split):\n",
    "        self.tree = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "\n",
    "    # we must concatenate X and y into one dataset for the build function, so we do not have to do that everytime we want to calculate the best mse split\n",
    "    def fit_tree(self, X, y):\n",
    "        y = y.rename(columns={0: X.shape[1]})\n",
    "        train = pd.concat([X,y], axis=1)\n",
    "        # call recursive build function to create Regression Tree\n",
    "        self.tree = build(train, self.min_samples_split)\n",
    "\n",
    "    # predicting y_values for each feature vector in X_test\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for c, r in X.iterrows():\n",
    "            y.append(navigate_tree(self.tree, r))\n",
    "        return np.array(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd8ee9-bb7a-44db-9f13-61d2e3117f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.965173482894897\n"
     ]
    }
   ],
   "source": [
    "# example usage \n",
    "import time\n",
    "time_start = time.time()\n",
    "rt = RegressionTree(100)\n",
    "rt.fit_tree(X_train, y_train)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc1c73d-0a7e-48e4-8648-fdb2d703ebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Regression Tree [0.564149934111509, 0.5562763931984445, 0.54529052229588, 0.5460526596305798, 0.5352970039120369, 0.5281137842063388, 0.5293288726542907, 0.5295109644819089, 0.5272827216221708, 0.5268003052114307]\n",
      "Sklearns regression tree [0.5643695746013677, 0.5597546160610247, 0.5453528888754455, 0.5460526596305798, 0.5352970039120369, 0.5281137842063388, 0.5293288726542907, 0.5295109644819089, 0.5272827216221708, 0.5268003052114307]\n",
      "MSE difference between sklearn's Decision Regressor and my Regression Tree: 1.2150165816808075e-06\n"
     ]
    }
   ],
   "source": [
    "# Running time -> a few minutes\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# We create a RegressionTree and DecisionTreeRegressor, using a variety of min_samples_split values (the only hyperparameter for the RegressionTree)\n",
    "# we then fit the trees on X_train and y_train and allow them to make predictions on X_test\n",
    "# we calculate the mse between predictions and y_test, and append them to an array.\n",
    "rt_mse = []\n",
    "scikit_rt_mse = []\n",
    "for i in range(50,501,50):\n",
    "    rt = RegressionTree(i)\n",
    "    rt.fit_tree(X_train, y_train)\n",
    "\n",
    "    scikit_rt = DecisionTreeRegressor(criterion='squared_error', min_samples_split = i)\n",
    "    scikit_rt.fit(X_train, y_train)\n",
    "\n",
    "    rt_prediction = rt.predict(X_test)\n",
    "    rt_mse.append(mean_squared_error(y_test, rt_prediction))\n",
    "    scikit_prediction = scikit_rt.predict(X_test)\n",
    "    scikit_rt_mse.append(mean_squared_error(y_test, scikit_prediction))\n",
    "\n",
    "# Just by printing the arrays, we see the results are very similiar for min_samples_split ranging from 50 to 500\n",
    "print(f\"My Regression Tree {rt_mse}\")\n",
    "print(f\"Sklearns regression tree {scikit_rt_mse}\")\n",
    "# we can go a step further and calculate mse between the two arrays, as mse is just calculating difference in results\n",
    "final_mse = mean_squared_error(rt_mse, scikit_rt_mse)\n",
    "print(\"\")\n",
    "print(f\"MSE difference between sklearn's Decision Regressor and my Regression Tree: {final_mse}\"\n",
    "\n",
    "# extremely small, meaning my implementation is likely correct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665477d0-bb50-40cd-9f3a-2bcf20a45e28",
   "metadata": {},
   "source": [
    "### Ensemble of Regression Trees\n",
    "\n",
    "Next we will look at an Ensemble of Regression Trees implementation which uses the RegressionTree class:\n",
    "\n",
    "To fit the tree, we initially set the residuals to just be the target values $y$ (of the training set). We call a RegressionTree with min_samples_split[$i$], where min_samples_split is an array in which each index represents the min_samples_split hyperparameter of each tree $T_i$.\n",
    "\n",
    "We fit the first tree $T_0$ with $X$_train and the residuals which are just the target values $y$, and then modify the total predictions (currently an array of 0's)s uch that we add the predictions of $T_0$ on $y$. In subsequent iterations, $T_i$ is trained with the residuals, which is the difference between the target values $y$ and the current total predictions $y_pred$, and we of course append the constructed trees to an array.\n",
    "\n",
    "When we want to predict a $y$-value, we just feed each $T_i$ the test data $X$, and add those predictions to a final value $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d5f19-226a-4afb-b78b-03ab57d41db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegressionTreeEnsemble class\n",
    "class RegressionTreeEnsemble:\n",
    "\n",
    "    # We store n -> number of trees to be implemented and min_samples_split, an array representing the min_samples_split values for n trees\n",
    "    def __init__(self, n, min_samples_split):\n",
    "        self.n = n\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "\n",
    "    # fit function explained above\n",
    "    def fit_tree(self, X, y):\n",
    "        if not self.n <= 0:\n",
    "            y_pred = pd.DataFrame(0, index=y.index, columns=y.columns)\n",
    "            for i in range(self.n):\n",
    "                residuals = y - y_pred\n",
    "                tree_n = RegressionTree(self.min_samples_split[i])\n",
    "                tree_n.fit_tree(X, residuals)\n",
    "                y_pred += pd.DataFrame(tree_n.predict(X), index=y.index, columns=y.columns)         \n",
    "                self.trees.append(tree_n)\n",
    "\n",
    "    # predict function explained above\n",
    "    def predict(self, X):\n",
    "        if not self.trees:\n",
    "            return np.array([])\n",
    "\n",
    "        # first declare y as a matrix of 0's, since we add our predictions onto it from each tree\n",
    "        y = np.full(X.shape[0], 0, dtype=np.float64)\n",
    "        for tree in self.trees:\n",
    "            y += tree.predict(X)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db9ec7-ce1b-46b2-9e26-bc24171f1c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2122782953.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;31m# example usage -> takes a few minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionTreeEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2303544942.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtree_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtree_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/812297374.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# call recursive build function to create Regression Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2784666421.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# recursively build left and right child of current node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# using the left and right split respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mleft_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mright_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2784666421.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# recursively build left and right child of current node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# using the left and right split respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mleft_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mright_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2784666421.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# recursively build left and right child of current node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# using the left and right split respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mleft_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mright_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2784666421.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# recursively build left and right child of current node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# using the left and right split respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mleft_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mright_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/2784666421.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# find the best mse split for the current dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_mse_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# no split could be found, make it a leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# no non-empty split could be found -> remember if we had duplicate feature vectors for our entire dataset, no split could be found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/dcs-tmp.u2256152/ipykernel_246074/1438493563.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mleft_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mright_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mleft_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# we skip duplicate values, if our current dataframe only contains duplicate feature vectors, the algorithm will try to split the dataframe into two, which should be avoided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mleft_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_split_y_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_split_y_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4207\u001b[0m         \u001b[0mAssumes\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mboth\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4208\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mCaller\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mresponsible\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchecking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4209\u001b[0m         \"\"\"\n\u001b[1;32m   4210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4211\u001b[0;31m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4214\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4010\u001b[0m             \u001b[0mcol_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4011\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4013\u001b[0m             \u001b[0;31m# this is a cached value, mark it so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4014\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4015\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, item, cacher)\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \u001b[0mcacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \"\"\"\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6317\u001b[0m         \u001b[0;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6318\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6320\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6322\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# example usage -> takes a few minutes\n",
    "min_samples = [500, 400, 300, 200, 100]\n",
    "rte = RegressionTreeEnsemble(5, min_samples)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "print(f\"MSE produced by an Ensemble Regression Tree: {mean_squared_error(y_test, rte_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cde34b-7bf7-4242-86f2-7e9620bf7b09",
   "metadata": {},
   "source": [
    "### Hyperparameter Fine-tuning\n",
    "\n",
    "To achieve the best performance out of the Ensemble Regression Tree on our dataset, fine-tuning of the hyperparameter min_samples_split is required. For the RegressionTree implementation, it may be possible to iterate over a range of min_samples_split value and take the one that yields the lowest MSE, but due to how expensive it is to fit an EnsembleRegressionTree (taking a few minutes each) and the fact that each tree can have different min_samples_split values, careful fine-tuning is required to find a good performing set of min_samples_split parameters whilst also not taking days or weeks to find them. To do this, some hyperparameter fine tuning libraries were used:\n",
    "\n",
    "#### Skopt\n",
    "\n",
    "Also known as Scikit Optimize, it has a function gp_minimize, which takes an objective function (which we define in our code) and a set of potential parameters, which for the Ensemble Regression Tree is a range from 2 to 500 for each tree in the Ensemble. It uses Bayesian Optimisation based on a Gaussian Process Model, which first samples the hyperparameter space by evaluating the objective function at random points, and then fits a probabilistic model to predict the objective function in the hyperparameter space. Iteratively, it selects a point of interest and evaluates the objective function at that point, and updates its model to predict where the global minima of the function is. \n",
    "\n",
    "This is used with initially 30 calls to the objective function, which took around 4000 seconds to complete, and did not show promising results.\n",
    "\n",
    "#### Mango\n",
    "\n",
    "Mango is a parallel hyperparameter tuning library that is capable of fine-tuning in parallel and also uses search techniques based on Bayesian Optimisation. This library is in use by ARM with its main feature being parallelisation. \n",
    "\n",
    "This library gave much more promising results than Skopt, however running in parallel does take longer, as we do not split the workload between cores, we let each thread find a minima in parallel, so the number of calls to the objective function is the same for each core as it is for one core.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c787771-a48e-4688-bce4-80877e49e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arm-mango\n",
      "  Using cached arm_mango-1.4.3-py3-none-any.whl (29 kB)\n",
      "Collecting attrdict>=2.0.1\n",
      "  Using cached attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from arm-mango) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>=0.21.3 in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from arm-mango) (1.5.2)\n",
      "Collecting tqdm>=4.36.1\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from arm-mango) (1.13.1)\n",
      "Requirement already satisfied: six in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from attrdict>=2.0.1->arm-mango) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from scikit_learn>=0.21.3->arm-mango) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages (from scikit_learn>=0.21.3->arm-mango) (1.4.2)\n",
      "Installing collected packages: tqdm, attrdict, arm-mango\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 30] Read-only file system: '/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/tqdm'\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement skopt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for skopt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# this did not work in my jupter notebook due to permissions, so was done in VSC on the DCS system\n",
    "!pip install arm-mango\n",
    "!pip install skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d39888-a425-4d49-8d8f-8dd743fe6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple objective function to be optimised\n",
    "def obj_func_skopt(min_samples_split):\n",
    "    # uncomment line below if does not work\n",
    "    # min_samples_split = [p0, p1, p2, p3, p4]\n",
    "    model = RegressionTreeEnsemble(5, min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827427c-a8ae-4003-8982-4d56346d0b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gp_minimize\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integer\n\u001b[1;32m      4\u001b[0m search_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "# Skopt implementation\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "\n",
    "# this took about an hour\n",
    "search_space = list()\n",
    "for i in range(5):\n",
    "    search_space.append(Integer(2, 500, name=f\"p{i}\"))\n",
    "time_start = time.time()\n",
    "result = gp_minimize(obj_func_skopt, search_space, n_calls=30)\n",
    "print(result)\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "# ok results\n",
    "# fun: 0.5690001631619772\n",
    "# x: [np.int64(165), np.int64(69), np.int64(194), np.int64(169), np.int64(173)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c6795-4dc4-42ca-aff1-151dafe41f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mango'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mango implementation \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmango\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuner, scheduler\n\u001b[1;32m      4\u001b[0m param_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mango'"
     ]
    }
   ],
   "source": [
    "# Mango implementation \n",
    "from mango import Tuner, scheduler\n",
    "\n",
    "param_space = dict()\n",
    "for i in range(5):\n",
    "    param_space[f'p{i}'] = range(2,500)\n",
    "\n",
    "# Using 4 threads/cores and running in parallel -> 80 iterations total technically\n",
    "config = {\n",
    "    'num_iteration': 20,  \n",
    "    'batch_size': 4     \n",
    "}\n",
    "\n",
    "\n",
    "@scheduler.parallel(n_jobs=4)\n",
    "def obj_func_mango(**params):\n",
    "    min_samples_split = [params['p0'],params['p1'],params['p2'],params['p3'],params['p4']]\n",
    "    model = RegressionTreeEnsemble(5, min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse\n",
    "\n",
    "# Took about 0.75 hours (less iterations than skopt)\n",
    "tuner = Tuner(param_space, obj_func_mango, config)\n",
    "time_start = time.time()\n",
    "results = tuner.minimize()  # Run Tuner\n",
    "best_params = results[\"best_params\"]\n",
    "best_objective = results[\"best_objective\"]\n",
    "print(f'Optimal value of parameters: {best_params} and objective: {best_objective}')\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "\n",
    "# Best score: 0.5036546753541488: 100%|█████████████████████████████████████████████| 20/20 [46:45<00:00, 140.30s/it]\n",
    "# Optimal value of parameters: {'p0': 275, 'p1': 371, 'p2': 240, 'p3': 400, 'p4': 333} and objective: 0.5036546753541488\n",
    "# Found betrter set of parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba1494-c660-4506-b488-07de064c41b2",
   "metadata": {},
   "source": [
    "### Another Approach\n",
    "\n",
    "To try get below 0.5 mse, we opted for finding the hyperparameters for each tree in the Ensemble one at a time instead of all at once. We alter our objective function to instead fit an Ensemble Tree with 5 trees, to fit an Ensemble with len(min_samples_split). And then we tell our optimiser to optimise on 1 tree first, finding the optimal min_samples_split $m_0$ for $T_0$, and then we tell our optimiser to optimise on 2 trees, where $m_0$ is already given and the optimiser must find $m_1$, so at each $T_i$ we are trying to find $m_i$ only and we are given all $m_0$ to $m_{i-1}$ already.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa82d8-2d1c-4b39-be07-2b48442716a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# new objective function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;129m@scheduler\u001b[39m\u001b[38;5;241m.\u001b[39mparallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m      4\u001b[0m     min_samples_split \u001b[38;5;241m=\u001b[39m  []\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(params)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "# new objective function\n",
    "from mango import Tuner, scheduler\n",
    "\n",
    "@scheduler.parallel(n_jobs=4)\n",
    "def obj_func_mango_two(**params):\n",
    "    min_samples_split =  []\n",
    "    for i in range(len(params)):\n",
    "        min_samples_split.append(params[f'p{i}'])\n",
    "    model = RegressionTreeEnsemble(len(min_samples_split), min_samples_split)\n",
    "    model.fit_tree(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_true = y_test, y_pred = predictions)\n",
    "    return mse\n",
    "\n",
    "current_optimal_params = []\n",
    "optimal_params_mse = []\n",
    "\n",
    "time_start = time.time()\n",
    "# iterating over each tree we want to find min_samples_split value for\n",
    "for n in range(1,6):\n",
    "    print(f\"finding minimizer for tree {n}\")\n",
    "    print(current_optimal_params)\n",
    "    print(optimal_params_mse)\n",
    "    param_space = dict()\n",
    "    # define the parameter space with values ranging from 2 to 500\n",
    "    for i in range(n):\n",
    "        param_space[f'p{i}'] = range(2,500)\n",
    "    # then, if we have already found optimal parameters for some trees we replace them in the parameter space with just a singular value\n",
    "    for i in range(len(current_optimal_params)):\n",
    "        param_space[f'p{i}'] = range(current_optimal_params[i], current_optimal_params[i]+1)\n",
    "\n",
    "    # This time 4 cores run in parallel and 20 calls to the objective function are made\n",
    "    config = {\n",
    "        'num_iteration': 20,  \n",
    "        'batch_size': 4 \n",
    "    }\n",
    "\n",
    "    tuner = Tuner(param_space, obj_func_mango_two, config)\n",
    "    results = tuner.minimize()  # Run Tuner\n",
    "    # we store the best mss in an array, and the mse for each mss\n",
    "    best_params = results[\"best_params\"]\n",
    "    current_optimal_params.append(best_params[f\"p{n-1}\"])\n",
    "    optimal_params_mse.append(results[\"best_objective\"])\n",
    "\n",
    "\n",
    "print(f\"Optimal min_samples_split array: {current_optimal_params}\")\n",
    "print(f\"The best mse for each tree: {optimal_params_mse}\")\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "# Best score: 0.4963636646680849: 100%|██████████████████████████████████████████████| 20/20 [25:27<00:00, 76.39s/it]\n",
    "# [448, 464, 314, 374, 411]\n",
    "# [np.float64(0.5262064484548055), np.float64(0.5124900174963549), np.float64(0.5123641383276403), np.float64(0.49426267905059706), np.float64(0.4963636646680849)]\n",
    "# 4666.020900964737\n",
    "# num_iteration 20, batch_size 4, n_jobs 4\n",
    "# Took about 1-1.5 hours, we found a set of parameters yielding an mse of under 0.5\n",
    "# We increased the iterations to 50, batch_size to 5, still got the same result just took longer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ca445-9b84-4cf3-83ae-1f0e0f867490",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation\n",
    "\n",
    "Next, to try get an even lower MSE, we implemented K-Fold Cross Validation on our training set $X_train$ in the objective function. This would multiply the time it takes to find a set of optimal parameters by 5 using $K=5$, but would help reduce overfitting to training data as we would train and test on a validation set using 5 different folds on the training set, then taking the average mse values of those folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc57c27-cdb8-4870-96ba-ca59ffa92c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# New redefined objective function\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;129m@scheduler\u001b[39m\u001b[38;5;241m.\u001b[39mparallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m     22\u001b[0m     min_samples_split \u001b[38;5;241m=\u001b[39m  []\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(params)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Since our Ensemble Tree model is not an \"Estimator\" as required by the cross_val_score function from sklearn\n",
    "# we can easily convert this by creating a class inheriting from BaseEstimator and RegressorMixin\n",
    "class EnsembleTreeEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, min_samples_split):\n",
    "        self.min_samples_split = min_samples_split\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        self.model = RegressionTreeEnsemble(len(self.min_samples_split), self.min_samples_split)\n",
    "        self.model.fit_tree(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "# New redefined objective function\n",
    "@scheduler.parallel(n_jobs=4)\n",
    "def obj_func_mango_cv(**params):\n",
    "    min_samples_split =  []\n",
    "    for i in range(len(params)):\n",
    "        min_samples_split.append(params[f'p{i}'])\n",
    "    model = EnsembleTreeEstimator(min_samples_split=min_samples_split)\n",
    "    # Using Sklearn's KFold to automatically train and test on 5 different folds of the training set of data\n",
    "    # using mse still as our metric\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "    mse_scores = -mse_scores\n",
    "    return mse_scores.mean()\n",
    "\n",
    "# Following the same process as before, extending our param space range from 2 to 600 instead of 2 to 500\n",
    "current_optimal_params = []\n",
    "optimal_params_mse = []\n",
    "\n",
    "time_start = time.time()\n",
    "for n in range(1,6):\n",
    "    print(f\"finding minimizer for tree {n}\")\n",
    "    print(current_optimal_params)\n",
    "    print(optimal_params_mse)\n",
    "    param_space = dict()\n",
    "    for i in range(n):\n",
    "        param_space[f'p{i}'] = range(2,600)\n",
    "    for i in range(len(current_optimal_params)):\n",
    "        param_space[f'p{i}'] = range(current_optimal_params[i], current_optimal_params[i]+1)\n",
    "        print(param_space[f'p{i}'])\n",
    "\n",
    "    config = {\n",
    "        'num_iteration': 20,  \n",
    "        'batch_size': 4   \n",
    "    }\n",
    "\n",
    "    tuner = Tuner(param_space, obj_func_mango_cv, config)\n",
    "    results = tuner.minimize()\n",
    "    best_params = results[\"best_params\"]\n",
    "    current_optimal_params.append(best_params[f\"p{n-1}\"])\n",
    "    optimal_params_mse.append(results[\"best_objective\"])\n",
    "\n",
    "print(f\"Optimal min_samples_split array: {current_optimal_params}\")\n",
    "print(f\"The best mse for each tree: {optimal_params_mse}\")\n",
    "time_end = time.time()\n",
    "print(f\"Time taken {time_end-time_start}\")\n",
    "\n",
    "# This yielded poor results, similar to the skopt optimiser\n",
    "# Best score: 0.5469522986173644: 100%|███████████████████████████████████████████| 20/20 [1:58:46<00:00, 356.32s/it]\n",
    "# [169, 501, 473, 520, 508]\n",
    "# [np.float64(0.5526849348267582), np.float64(0.5332538801811244), np.float64(0.5363925896434576), np.float64(0.536249048073956), np.float64(0.5469522986173644)]\n",
    "# 22088.729598522186\n",
    "# Took a very long time - several hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66ba30-4464-4f8b-8807-3efbf1dda921",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Using Cross fold validation did not pair well with the mango optimiser, this may be due to selecting hyperparameters that overfit for the training set, as the testing set is not used at all in that optimiser. As a result, it chose a very low min_samples_split value for the first tree, which resulted in a very average mse value overall for the Ensemble. When actually testing the set of hyper-parameters $[169, 501, 473, 520, 508]$ on our test data, we obtain an mse of $0.5237462918578$\n",
    "\n",
    "Our best performing optimiser was using Mango and finding the mss for each tree separately instead of all at once, which gave an mse of around $0.496$ with the array of mss being $[448, 464, 314, 374, 411]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5d601-f5ff-4628-b110-c57d492cb49d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m min_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m448\u001b[39m,\u001b[38;5;241m464\u001b[39m,\u001b[38;5;241m314\u001b[39m,\u001b[38;5;241m374\u001b[39m,\u001b[38;5;241m411\u001b[39m]\n\u001b[1;32m      2\u001b[0m rte \u001b[38;5;241m=\u001b[39m RegressionTreeEnsemble(\u001b[38;5;241m5\u001b[39m, min_samples)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrte\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rte_predictions \u001b[38;5;241m=\u001b[39m rte\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE produced by an Ensemble Regression Tree with best parameters found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_squared_error(y_test,\u001b[38;5;250m \u001b[39mrte_predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mRegressionTreeEnsemble.fit_tree\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m residuals \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m y_pred\n\u001b[1;32m     16\u001b[0m tree_n \u001b[38;5;241m=\u001b[39m RegressionTree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split[i])\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtree_n\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(tree_n\u001b[38;5;241m.\u001b[39mpredict(X), index\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mcolumns)         \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree_n)\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mRegressionTree.fit_tree\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X,y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# call recursive build function to create Regression Tree\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_samples_split\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# recursively build left and right child of current node\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# using the left and right split respectively\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m left_child \u001b[38;5;241m=\u001b[39m \u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_split\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m right_child \u001b[38;5;241m=\u001b[39m build(df\u001b[38;5;241m.\u001b[39miloc[right_split], min_samples)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(mse, feature, value, left_child, right_child)\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(df, min_samples)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# find the best mse split for the current dataset\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m mse, feature, value, left_split, right_split \u001b[38;5;241m=\u001b[39m \u001b[43mbest_mse_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# no split could be found, make it a leaf node\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# no non-empty split could be found -> remember if we had duplicate feature vectors for our entire dataset, no split could be found\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# as the mse is never updated, so we return the mean of ground truth values\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mse \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39minf:\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mbest_mse_split\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):  \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# this is O(1), instead of recalculating the mse for the dataset, we can incrementally add an example to the left split and remove it from the right\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Since calculating mse with the traditional formula takes O(n), by sorting the current feature, we can incrementally control the size of each split\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# and calculate mse of each split in constant time\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     left_split_y_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[0;32m---> 31\u001b[0m     left_split_y_squared_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     32\u001b[0m     right_split_y_sum \u001b[38;5;241m=\u001b[39m total_y_sum \u001b[38;5;241m-\u001b[39m left_split_y_sum\n\u001b[1;32m     33\u001b[0m     right_split_y_squared_sum \u001b[38;5;241m=\u001b[39m total_y_squared_sum \u001b[38;5;241m-\u001b[39m left_split_y_squared_sum\n",
      "File \u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/indexing.py:1722\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[1;32m   1721\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCDataFrame\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using .loc for automatic alignment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1726\u001b[0m     )\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "File \u001b[0;32m/local/java/python-venv-packages.cs342/venv/lib/python3.9/site-packages/pandas/core/dtypes/generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_samples = [448,464,314,374,411]\n",
    "rte = RegressionTreeEnsemble(5, min_samples)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "print(f\"MSE produced by an Ensemble Regression Tree with best parameters found: {mean_squared_error(y_test, rte_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf9618-9b92-4703-a854-f80f97358368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m rte\u001b[38;5;241m.\u001b[39mfit_tree(X_train, y_train)\n\u001b[1;32m      4\u001b[0m rte_predictions \u001b[38;5;241m=\u001b[39m rte\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE produced by an Regression Tree with best parameter found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_squared_error(y_test,\u001b[38;5;250m \u001b[39mrte_predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# we see the Ensemble Regression Tree outperforms the basic Regression Tree\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "# In comparison with a single tree\n",
    "rte = RegressionTree(448)\n",
    "rte.fit_tree(X_train, y_train)\n",
    "rte_predictions = rte.predict(X_test)\n",
    "print(f\"MSE produced by an Regression Tree with best parameter found: {mean_squared_error(y_test, rte_predictions)}\")\n",
    "\n",
    "# we see the Ensemble Regression Tree outperforms the basic Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de78950-262d-46a4-8611-d5269e3bf062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
